includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/csv/csv_parser.config"

/**
*   Namespace for handling input parsing and parameter settings based on inputs
*/
input_handler {
    /**
    *   If input CSV is given, parse and convert into format produced by direct YAML input
    */
    convert_csv_inputs = {
        if (!params.containsKey('input_csv') || params.containsKey('input')) {
            return;
        }

        def common_cols = [
            'patient',
            'sample',
            'state'
        ];

        def input_types = [
            'BAM': [
                'cols': ['path']
            ],
            'FASTQ': [
                'cols': [
                    'read_group_identifier',
                    'sequencing_center',
                    'library_identifier',
                    'platform_technology',
                    'platform_unit',
                    'bam_header_sm',
                    'lane',
                    'read1_fastq',
                    'read2_fastq'
                ]
            ],
            'SRC': [
                'cols': [
                    'src_input_type',
                    'src_input_algorithm',
                    'src_path'
                ],
                'key_map': [
                    'src_input_type': 'src_input_type',
                    'src_input_algorithm': 'algorithm',
                    'src_path': 'path'
                ]
            ]
        ];

        def reader = new BufferedReader(new FileReader(params.input_csv));
        def header_cols = reader.readLine().split(',') as List;

        def cols_to_parse = [];
        def types_to_parse = [];

        // Make sure common columns are given
        assert header_cols.containsAll(common_cols) : "The given input CSV does not contain the expected common columns: `${common_cols}`";
        cols_to_parse += common_cols;

        input_types.each { type, type_info ->
            if (header_cols.containsAll(type_info.cols)) {
                types_to_parse += type;
                cols_to_parse += type_info.cols;
            }
        }

        def given_csv_inputs = csv_parser.parse_csv(params.input_csv, cols_to_parse, true);

        def given_inputs = [:];
        given_csv_inputs.each { csv_row ->
            if (!given_inputs.containsKey(csv_row.patient)) {
                given_inputs[csv_row.patient] = [:];
            }

            if (!given_inputs[csv_row.patient].containsKey(csv_row.sample)) {
                given_inputs[csv_row.patient][csv_row.sample] = ['state': csv_row.state];
            } else {
                assert csv_row.state == given_inputs[csv_row.patient][csv_row.sample]['state'] : "Multiple states were given for the sample `${csv_row.sample}`! Each sample should have only one state."
            }

            def col_key = null;
            def parsed_map = [:];
            types_to_parse.each { parse_type ->
                parsed_map = [:];
                input_types[parse_type]['cols'].each { col_to_parse ->
                    col_key = (input_types[parse_type].containsKey('key_map')) ? input_types[parse_type]['key_map'][col_to_parse] : col_to_parse;
                    parsed_map[col_key] = csv_row[col_to_parse];
                }

                if (parsed_map.any{ parsed_val -> !parsed_val.value }) {
                    System.out.println("INFO - Found empty fields for `${parse_type}` on row `${csv_row}` - skipping.");
                    return;
                }

                if (parse_type == 'BAM') {
                    if (given_inputs[csv_row.patient][csv_row.sample].containsKey('BAM')) {
                        if (given_inputs[csv_row.patient][csv_row.sample]['BAM'] != parsed_map) {
                            throw new IllegalArgumentException("Sample `${csv_row.sample}` for patient `${csv_row.patient}` was given multiple BAMs! Only a single BAM per sample should be given.");
                        }
                    }

                    given_inputs[csv_row.patient][csv_row.sample]['BAM'] = parsed_map;
                } else {
                    if (!given_inputs[csv_row.patient][csv_row.sample].containsKey(parse_type)) {
                        given_inputs[csv_row.patient][csv_row.sample][parse_type] = [];
                    }

                    if (given_inputs[csv_row.patient][csv_row.sample][parse_type].contains(parsed_map)) {
                        System.out.println("INFO - Found duplicate entry in CSV: `${parsed_map}` for type `${parse_type}` - the duplicate will be skipped.");
                    } else {
                        given_inputs[csv_row.patient][csv_row.sample][parse_type] << parsed_map;
                    }
                }
            }
        }

        params.input = given_inputs;
    }

    /**
    *   Verify inputs and determine input type
    */
    check_inputs = {
        if (!params.containsKey('input')) {
            throw new IllegalArgumentException("No input found! Please run pipeline with inputs.");
        }

        // TO-DO: load inputs into local variable to allow for manipulation
        def given_input_types = [] as Set;
        def given_src_types = [] as Set;
        def samples_found = [];
        def given_src_algorithms = ['SNV': [] as Set, 'CNA': [] as Set];
        params.input.each { patient, patient_data ->
            patient_data.each { sample, sample_data ->
                if (samples_found.contains(sample)) {
                    throw new IllegalArgumentException("Found duplicate sample: `${sample}`. Samples given must be unique!");
                }
                samples_found << sample;
                def sample_input_keys = sample_data.keySet() as List;
                sample_input_keys.removeAll{ it == 'state' };
                if (sample_input_keys.contains('CRAM')) {
                    sample_input_keys.removeAll{ it == 'CRAM' };
                    sample_input_keys.add('BAM');
                    sample_data['BAM'] = sample_data['CRAM'];
                    sample_data.remove('CRAM');
                }
                sample_input_keys.each { sample_input_type -> given_input_types.add(sample_input_type) };

                if (sample_data.state == 'tumor') { // Only look for and handle SRC inputs for tumor samples
                    if (sample_input_keys.contains('SRC')) {
                        def sample_src_types = [] as Set;
                        sample_data.SRC.each { src_input ->
                            sample_src_types.add(src_input.src_input_type);
                            given_src_algorithms[src_input.src_input_type].add(src_input.algorithm);
                        }

                        given_src_types.add(sample_src_types as List);
                        assert given_src_types[0].sort() == given_src_types[-1].sort()
                            : "Received mismatching SRC input types: `${given_src_types[0]}` and `${given_src_types[-1]}`. If SRC input is given, the same types must be given for all samples."
                    }
                }
            }
        }

        String input_type = null;

        if (given_input_types.isEmpty()) {
            throw new IllegalArgumentException("No expected inputs found! Please ensure the inputs contain proper inputs including either BAM/CRAM or FASTQ and optionally SRC")
        }

        Boolean src_input_given = false;
        if (given_input_types.contains('SRC')) {
            src_input_given = true;
            given_input_types.removeAll{ it == 'SRC' };
            input_type = 'SRC';
        }

        // Only one of FASTQ and BAM is allowed if given
        if (!given_input_types.isEmpty()) {
            assert given_input_types.size() == 1 : "Expected only one of BAM/CRAM or FASTQ for sequence input but received `${given_input_types}`";
            input_type = given_input_types[0];
        }

        // A single input type should be left
        params.input_type = input_type;
        params.src_input_given = src_input_given;
        params.src_input_types = src_input_given ? given_src_types[0] : [];

        // Check that the bam_header_sm is the same as sample for FASTQ input
        if (input_type == 'FASTQ') {
            params.input.each { patient, patient_data ->
                patient_data.each { sample, sample_data ->
                    sample_data.FASTQ.each { fastq_data ->
                        assert fastq_data.bam_header_sm == sample : "Input FASTQs must have matching sample and bam_header_sm! Received `${fastq_data.bam_header_sm}` for sample: `${sample}`";
                    }
                }
            }
        }

        // Check that the same inputs have been given for all samples
        def given_inputs_per_state = ['normal': [] as Set, 'tumor': [] as Set];
        params.input.each { patient, patient_data ->
            patient_data.each { sample, sample_data ->
                def sample_input_keys = sample_data.keySet() as List;
                sample_input_keys.removeAll{ it == 'state' };
                sample_input_keys.each { input_key -> given_inputs_per_state[sample_data.state].add(input_key.replace('CRAM', 'BAM')) };

                def expected_normal = 0;
                def expected_tumor = 0;
                if (params.input_type == 'SRC') {
                    expected_normal = 0;
                    expected_tumor = 1;
                } else {
                    expected_normal = 1;
                    expected_tumor = params.src_input_given ? 2 : 1;
                }

                if (sample_data.state == 'normal') {
                    assert given_inputs_per_state.normal.size() == expected_normal : "Expected `${expected_normal}` number of inputs for normal samples!";
                    assert !given_inputs_per_state.normal.contains('SRC') : "SRC inputs should not be given for normal samples!";
                } else {
                    assert given_inputs_per_state.tumor.size() == expected_tumor : "Expected `${expected_tumor}` number of inputs for tumor samples!";
                    if (params.src_input_given) {
                        assert given_inputs_per_state.tumor.contains('SRC') : "Tumor samples need to be provided with the same SRC input types across all tumor samples!"
                    }
                }
            }
        }

        if (input_type == 'SRC') {
            assert params.src_input_types.containsAll(['SNV', 'CNA']) : "SRC input detected but only `${params.src_input_types}` given. Please provide both ['SNV', 'CNA'].";
            System.out.println("INFO - Only SRC input detected. SRC precursors will be disabled.");
            params.override_src_precursor_disable = false;
        }

        if (params.requested_pipelines.contains('call-SRC')) {
            // Check that a single algorithm is given for each SRC input type
            // and verify selection of SNV and CNA tool matches pipeline algorithm selections
            given_src_algorithms.each { given_type, given_algorithms ->
                if (given_algorithms) {
                    assert given_algorithms.size() == 1 : "Received multiple algorithms for ${given_type}: `${given_algorithms}`. Please provide inputs from the same single algorithm for all samples.";

                    params["src_${given_type.toLowerCase()}_tool"] = given_algorithms[0];
                    return;
                }

                // No input provided for this type, ensure the selected tool is being run from the corresponding pipeline
                if (given_type == 'SNV') {
                    if (params.src_snv_tool == 'BCFtools-Intersect') {
                        assert params.pipeline_params.call_sSNV.algorithm.size() > 1 : "For selected SNV tool `${params.src_snv_tool}`, more than one SNV caller needs to be run! Please check and update the pipeline params for call-sSNV.";
                    } else {
                        assert params.pipeline_params.call_sSNV.algorithm.contains(params.src_snv_tool.toLowerCase()) : "Selected SNV algorithm `${params.src_snv_tool}` for SRC is not being run with call-sSNV! Please ensure the selected algorithm is selected to run."
                    }
                } else {
                    def algorithm_to_check = "";
                    if (params.src_cna_tool == 'FACETS') {
                        algorithm_to_check = 'cnv_facets';
                    } else {
                        algorithm_to_check = params.src_cna_tool.toLowerCase();
                    }

                    assert params.pipeline_params.call_sCNA.algorithm.contains(algorithm_to_check) : "Selected CNA algorithm `${params.src_cna_tool}` for SRC is not being run with call-sCNA! Please ensure the selected algorithm is selected to run."
                }
            }
        }
    }

    /**
    *   Get sample counts from input
    */
    set_sample_counts = {
        Map sample_counts = [:];
        params.input.each { patient, patient_data ->
            if (!sample_counts.containsKey(patient)) {
                sample_counts[patient] = ['normal': 0, 'tumor': 0];
            }
            patient_data.each { sample, sample_data ->
                sample_counts[patient][sample_data.state] += 1;
            }
        }

        params.sample_counts = sample_counts;
    }

    /**
    *   Check identified counts and run mode
    */
    check_sample_counts = {
        if (params.sample_mode != 'single' && params.input_type != 'SRC') {
            if (!params.sample_counts.every { patient, counts -> counts.normal == 1 }) {
                throw new Exception("Patients with multiple normal samples or no normal sample found! Please run the metapipeline with a single normal sample per patient.");
            }
        }

        return;
    }

    /**
    *   Check proper inputs provided for call-SRC in single-sample mode
    */
    check_src_inputs_for_single_sample_mode = {
        if (!(params.sample_mode == 'single' && params.requested_pipelines.contains('call-SRC'))) {
            return;
        }

        if (!params.src_input_types.contains('SNV')) {
            assert params.src_snv_tool == 'Mutect2' : "In single sample mode, only Mutect2 can be run. To run call-SRC, please either provide SNV calls or select Mutect2 as the tool to be used for SNV caling and subsequent reconstruction."
        }

        assert params.src_input_types.contains('CNA') : "Call-sCNA cannot run in single-sample mode. To run call-SRC in single-sample mode, please provide CNA calls as input."
    }

    /**
    *   Generate structure for default data
    */
    get_default_data_map = {
        Map alignment_outputs = [:];
        List aligners = params.pipeline_params.align_DNA.aligner ?: ['BWA-MEM2'];
        aligners.each{ aligner_tool ->
            alignment_outputs[aligner_tool] = ['BAM':''];
        }
        Map default_data_map = [
            'align-DNA': alignment_outputs,
            'call-sSNV': [:],
            'call-sCNA': [:],
            'recalibrate-BAM': ['BAM':'', 'contamination_table':''],
            'calculate-targeted-coverage': ['expanded-intervals': ''],
            'convert-BAM2FASTQ': []
        ];

        return default_data_map;
    }

    /**
    *   Generate the sample data structure for the pipeline run
    */
    generate_sample_data_map = {
        Map all_sample_data = [:];
        List original_data_keys = [];

        if (params.input_type == 'BAM') {
            original_data_keys = ['path'];
        } else {
            original_data_keys = [
                'read_group_identifier',
                'sequencing_center',
                'library_identifier',
                'platform_technology',
                'platform_unit',
                'bam_header_sm',
                'lane',
                'read1_fastq',
                'read2_fastq'
            ];
        }

        List original_src_data_keys = [
            'src_input_type',
            'algorithm',
            'path'
        ];

        params.input.each { patient, patient_data ->
            patient_data.each { sample, sample_data ->
                String sample_state = sample_data.state;

                Object original_data = (params.input_type == 'BAM') ? [:] : [];
                List original_src_data = [];
                Map curr_data = [:];
                if (params.input_type != 'SRC') { // Handle the BAM/CRAM or FASTQ input
                    if (params.input_type == 'BAM') {
                        original_data_keys.each{ data_key -> original_data[data_key] = sample_data[params.input_type][data_key] };
                    } else {
                        sample_data[params.input_type].each { sample_input ->
                            curr_data = [:];
                            original_data_keys.each{ data_key -> curr_data[data_key] = sample_input[data_key] };
                            original_data += curr_data;
                        }
                    }
                }

                if (params.src_input_given && sample_state == 'tumor') { // Handle the SRC input if given
                    sample_data['SRC'].each { sample_input ->
                        curr_data = [:];
                        original_src_data_keys.each{ data_key -> curr_data[data_key] = sample_input[data_key] };
                        original_src_data += curr_data;
                    }
                }

                Map default_data = input_handler.get_default_data_map();
                default_data += [
                    'patient': patient,
                    'state': sample_state,
                    'original_data': original_data,
                    'original_src_data': original_src_data
                ];

                all_sample_data[sample] = default_data;
            }
        }

        params.sample_data = all_sample_data;
        return;
    }

    /**
    *   Main function to handle input parsing and parameter setting
    */
    handle_inputs = {
        input_handler.check_inputs();
        input_handler.check_src_inputs_for_single_sample_mode();
        input_handler.set_sample_counts();
        input_handler.check_sample_counts();
        input_handler.generate_sample_data_map();
        return;
    }
}
