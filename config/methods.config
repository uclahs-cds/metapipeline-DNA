includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/schema/schema.config"
includeConfig "${projectDir}/external/pipeline-Nextflow-config/config/csv/csv_parser.config"
includeConfig "${projectDir}/config/pipeline_selector.config"

def get_submodule_version(submodule) {
    def manifest_locations = [new File("${projectDir}/external/${submodule}/nextflow.config"), new File("${projectDir}/external/${submodule}/pipeline/nextflow.config")]
    def submodule_manifest = null

    for (a_manifest in manifest_locations) {
        if ( a_manifest.exists() ) {
            submodule_manifest = a_manifest
            break
        }
    }

    def version = 'null'

    if ( ! submodule_manifest ) {
        System.out.println(" ### WARNING ### Manifest for ${submodule} not found!")
        return 'null'
    }

    submodule_manifest.eachLine { line ->
        curr_line = line.replaceAll('\\s', '')
        if (curr_line in String && curr_line.startsWith('version')) {
            version = curr_line.split('=')[-1].replaceAll('\'', '').replaceAll('\"', '')
        }
    }

    return version
}

methods {
    set_output_dirs = {
        def tz = TimeZone.getTimeZone("UTC")
        def date = new Date().format("yyyyMMdd'T'HHmmss'Z'", tz)

        def base_output_dir = "${params.output_dir}/${manifest.name}-${manifest.version}/${params.project_id}"
        params.log_output_dir = "${base_output_dir}/log-${manifest.name}-${date}"
        params.output_dir = "${base_output_dir}/main_workflow"
    }

    set_pipeline_logs = {
        trace.enabled = true
        trace.file = "${params.log_output_dir}/nextflow-log/trace.txt"

        timeline.enabled = true
        timeline.file = "${params.log_output_dir}/nextflow-log/timeline.html"
        
        report.enabled = true
        report.file = "${params.log_output_dir}/nextflow-log/report.html"
    }
    
    set_process = {
        process['withName:call_metapipeline_DNA'].executor = params.executor
        process['withName:call_metapipeline_DNA'].maxForks = params.max_parallel_jobs
        process['withName:call_metapipeline_DNA'].cpus = params.per_job_cpus
        process['withName:call_metapipeline_DNA'].memory = "${params.per_job_memory_GB}GB" as nextflow.util.MemoryUnit
        process['withName:call_metapipeline_DNA'].queue = params.partition
        process['withName:call_metapipeline_DNA'].clusterOptions = "${params.clusterOptions}"
        executor.submitRateLimit = "1/${params.cluster_submission_interval}min"
    }

    set_submodule_versions = {
        params.version_BAM2FASTQ  = get_submodule_version('pipeline-convert-BAM2FASTQ')
        params.version_align_DNA  = get_submodule_version('pipeline-align-DNA')
        params.version_call_gSNP  = get_submodule_version('pipeline-call-gSNP')
        params.version_call_sSNV  = get_submodule_version('pipeline-call-sSNV')
        params.version_call_mtSNV = get_submodule_version('pipeline-call-mtSNV')
        params.version_call_gSV   = get_submodule_version('pipeline-call-gSV')
        params.version_call_sSV   = get_submodule_version('pipeline-call-sSV')
    }

    set_env = {
        // Ensure leading work dir is set to a directory shared between nodes, eg. /hot
        if (params.ucla_cds) {
            if (! params.leading_work_dir.startsWith('/hot')) {
                throw new Exception("The leading_work_dir must be set to a common directory across nodes (ie. in /hot for ucla_cds). Received ${params.leading_work_dir} instead.")
            }
        }

        schema.check_path(params.leading_work_dir, 'w')
        workDir = params.leading_work_dir

        // Only skip the check if ucla_cds is set to false. In all other cases, perform the check.
        if (params.ucla_cds) {
            if (! params.pipeline_work_dir.startsWith('/scratch')) {
                System.out.println("Pipeline_work_dir is being set to a directory other than /scratch! Please be very careful about I/O operations and network latency!")
            }
        }

        // Setting the work_dir parameter for individual pipelines
        if (params.ucla_cds) {
            /**
             * By default, set the work_dir parameter to /scratch when not specified.
             *
             * WARNING: changing this directory can lead to high server latency and
             * potential disk space limitations. Change with caution! The 'workDir'
             * in Nextflow determines the location of intermediate and temporary files.
             */
            params.work_dir = (params.containsKey("work_dir") && params.work_dir) ? params.work_dir : "/scratch"
            schema.check_path(params.work_dir, 'w')
        } else {
            // If work_dir was specified as a param and exists or can be created, set workDir. Otherwise, let Nextflow's default behavior dictate workDir
            if (params.containsKey("work_dir") && params.work_dir) {
                schema.check_path(params.work_dir, 'w')
            } else {
                // If not ucla_cds and no work_dir is set, leave it as an empty string and let individual pipelines handle workDir
                params.work_dir = ''
            }
        }
    }

    parse_input = {
        if (params.containsKey('input')) { // if params.input exists then YAML input is used
            if (params.input.size() > 1) {
                throw new Exception("More than one input is specified in the YAML, please choose one of BAM or FASTQ")
            }
        } else if (params.containsKey('input_csv')) { // check if CSV input is used
            reader = new BufferedReader(new FileReader(params.input_csv))
            header_line = reader.readLine().split(',') // reads first line of input csv file and split by comma into list
            if (header_line.contains('read1_fastq')) { // for FASTQ csv
                def fastq_input_fields = ['patient', 'sample', 'state', 'index', 'read_group_identifier', 'sequencing_center', 'library_identifier', 'platform_technology', 'platform_unit', 'bam_header_sm', 'lane', 'read1_fastq', 'read2_fastq']
                params.input.FASTQ = csv_parser.parse_csv(params.input_csv, fastq_input_fields)
            } else if (header_line.contains('path')) { // for BAM csv
                def bam_input_fields = ['patient', 'sample', 'state', 'path']
                params.input.BAM = csv_parser.parse_csv(params.input_csv, bam_input_fields)
            } else {
                throw new Exception("input CSV does not follow the format for either BAM or FASTQ inputs")
            }
        } else {
            throw new Exception("Neither YAML nor CSV inputs found! Please run pipeline with inputs.")
        }

        params.input_type = (params.input.containsKey('BAM')) ? 'BAM' : 'FASTQ'
    }

    enable_pipelines = { List pipelines ->
        def pipeline_name_map = [
            'convert_BAM2FASTQ': 'convert-BAM2FASTQ',
            'align_DNA': 'align-DNA',
            'call_gSNP': 'call-gSNP',
            'call_sSNV': 'call-sSNV',
            'call_mtSNV': 'call-mtSNV',
            'call_gSV': 'call-gSV',
            'call_sSV': 'call-sSV'
        ]

        params.pipeline_params.each { k, v ->
            v.is_pipeline_enabled = pipelines.contains(pipeline_name_map[k])
        }
    }

    resolve_pipeline_selection = {
        def pipelines_to_run = pipeline_selector.get_pipelines(params.requested_pipelines, params.input_type)
        if (params.input_type == 'FASTQ') {
            // Do not allow overriding alignment and call-gSNP with FASTQ input
            params.override_realignment = false
            params.override_call_gsnp = false
            return pipelines_to_run
        }
        def pipelines_to_remove = []
        if (params.override_call_gsnp) {
            pipelines_to_remove.add('call-gSNP')
            params.override_realignment = true
        }
        if (params.override_realignment) {
            pipelines_to_remove.add('convert-BAM2FASTQ')
            pipelines_to_remove.add('align-DNA')
        }
        pipelines_to_run.removeAll { pipelines_to_remove.contains(it) }
        if (pipelines_to_run.isEmpty()) {
            throw new Exception("Current pipeline selection settings result in 0 pipelines being run. Please double-check settings.")
        }
        methods.enable_pipelines(pipelines_to_run)
    }

    set_up = {
        methods.set_output_dirs()
        methods.set_pipeline_logs()
        methods.set_process()
        methods.set_submodule_versions()
        methods.set_env()
        methods.parse_input()
        methods.resolve_pipeline_selection()
    }
}
